{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Neural Network Flow Predictions Training Best 3 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports of Libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u0PXjnRBCRuP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OQM6DvSnRXAe"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVSYn8SQQX1D",
    "outputId": "182190e2-fc27-4cd2-915e-7909925cf3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
      "Requirement already satisfied: namex in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.0)\n",
      "zsh:1: no matches found: tensorflow[and-cuda]\n",
      "Requirement already satisfied: keras-tuner in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras-tuner) (3.6.0)\n",
      "Requirement already satisfied: packaging in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras-tuner) (23.0)\n",
      "Requirement already satisfied: requests in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (1.24.3)\n",
      "Requirement already satisfied: rich in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (13.9.2)\n",
      "Requirement already satisfied: namex in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (3.12.1)\n",
      "Requirement already satisfied: optree in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from optree->keras->keras-tuner) (4.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from rich->keras->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from rich->keras->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/algotsjoholm/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow[and-cuda]\n",
    "!pip install keras-tuner --upgrade\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Gjzkx_mnCRpb"
   },
   "outputs": [],
   "source": [
    "#project_path = '/content/gdrive/MyDrive/Samhällsbyggnadsprogrammet/AH2179/Project/' # set your own project path\n",
    "#df=pd.read_csv(project_path+'preprocessingV4.csv',sep=';') #Jennifers path\n",
    "#project_path = '/content/gdrive/MyDrive/Project Applied AI/Data/' #Linneas path\n",
    "train_df=pd.read_csv('/Users/algotsjoholm/Downloads/preprocessingV5.csv',sep=';')\n",
    "train_df = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "4VLfhps6iiZ7",
    "outputId": "99d3f145-07c9-4583-a7a1-b77aab517728"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval_1</th>\n",
       "      <th>FLOW_SUM</th>\n",
       "      <th>SPEED_WEIGHTED_AVG</th>\n",
       "      <th>FLOW_NEXT_15_SUM</th>\n",
       "      <th>FLOW_PREV_5_SUM</th>\n",
       "      <th>FLOW_PREV_15_SUM</th>\n",
       "      <th>FLOW_PREV_60_SUM</th>\n",
       "      <th>SPEED_NEXT_15_AVG</th>\n",
       "      <th>SPEED_PREV_5_AVG</th>\n",
       "      <th>SPEED_PREV_15_AVG</th>\n",
       "      <th>SPEED_PREV_60_AVG</th>\n",
       "      <th>IS_WEEKDAY</th>\n",
       "      <th>Interval_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "      <td>197436.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>442.061387</td>\n",
       "      <td>43.357093</td>\n",
       "      <td>19.925567</td>\n",
       "      <td>661.870155</td>\n",
       "      <td>215.871168</td>\n",
       "      <td>640.875985</td>\n",
       "      <td>2431.370778</td>\n",
       "      <td>19.844674</td>\n",
       "      <td>19.908797</td>\n",
       "      <td>19.935569</td>\n",
       "      <td>20.064293</td>\n",
       "      <td>0.687529</td>\n",
       "      <td>14.263331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>82.307056</td>\n",
       "      <td>21.142930</td>\n",
       "      <td>2.362819</td>\n",
       "      <td>287.845567</td>\n",
       "      <td>100.108140</td>\n",
       "      <td>300.024576</td>\n",
       "      <td>1241.349348</td>\n",
       "      <td>2.135399</td>\n",
       "      <td>2.223883</td>\n",
       "      <td>2.132143</td>\n",
       "      <td>1.914030</td>\n",
       "      <td>0.463502</td>\n",
       "      <td>2.754295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.395607</td>\n",
       "      <td>1.685500</td>\n",
       "      <td>2.395607</td>\n",
       "      <td>4.005448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>371.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>18.976920</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>1155.000000</td>\n",
       "      <td>18.948944</td>\n",
       "      <td>19.000403</td>\n",
       "      <td>19.017471</td>\n",
       "      <td>19.117466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>442.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>20.109010</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>755.000000</td>\n",
       "      <td>2923.000000</td>\n",
       "      <td>20.056423</td>\n",
       "      <td>20.137072</td>\n",
       "      <td>20.173206</td>\n",
       "      <td>20.325783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>513.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>21.216875</td>\n",
       "      <td>887.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>883.000000</td>\n",
       "      <td>3501.000000</td>\n",
       "      <td>21.083684</td>\n",
       "      <td>21.169776</td>\n",
       "      <td>21.186965</td>\n",
       "      <td>21.290345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>35.560000</td>\n",
       "      <td>1254.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>1254.000000</td>\n",
       "      <td>4684.000000</td>\n",
       "      <td>24.257949</td>\n",
       "      <td>25.641731</td>\n",
       "      <td>24.576513</td>\n",
       "      <td>24.003175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Interval_1       FLOW_SUM  SPEED_WEIGHTED_AVG  FLOW_NEXT_15_SUM  \\\n",
       "count  197436.000000  197436.000000       197436.000000     197436.000000   \n",
       "mean      442.061387      43.357093           19.925567        661.870155   \n",
       "std        82.307056      21.142930            2.362819        287.845567   \n",
       "min       299.000000       1.000000            0.560000         33.000000   \n",
       "25%       371.000000      25.000000           18.976920        418.000000   \n",
       "50%       442.000000      48.000000           20.109010        770.000000   \n",
       "75%       513.000000      60.000000           21.216875        887.000000   \n",
       "max       584.000000     107.000000           35.560000       1254.000000   \n",
       "\n",
       "       FLOW_PREV_5_SUM  FLOW_PREV_15_SUM  FLOW_PREV_60_SUM  SPEED_NEXT_15_AVG  \\\n",
       "count    197436.000000     197436.000000     197436.000000      197436.000000   \n",
       "mean        215.871168        640.875985       2431.370778          19.844674   \n",
       "std         100.108140        300.024576       1241.349348           2.135399   \n",
       "min           8.000000         33.000000        100.000000           2.395607   \n",
       "25%         124.000000        356.000000       1155.000000          18.948944   \n",
       "50%         251.000000        755.000000       2923.000000          20.056423   \n",
       "75%         295.000000        883.000000       3501.000000          21.083684   \n",
       "max         436.000000       1254.000000       4684.000000          24.257949   \n",
       "\n",
       "       SPEED_PREV_5_AVG  SPEED_PREV_15_AVG  SPEED_PREV_60_AVG     IS_WEEKDAY  \\\n",
       "count     197436.000000      197436.000000      197436.000000  197436.000000   \n",
       "mean          19.908797          19.935569          20.064293       0.687529   \n",
       "std            2.223883           2.132143           1.914030       0.463502   \n",
       "min            1.685500           2.395607           4.005448       0.000000   \n",
       "25%           19.000403          19.017471          19.117466       0.000000   \n",
       "50%           20.137072          20.173206          20.325783       1.000000   \n",
       "75%           21.169776          21.186965          21.290345       1.000000   \n",
       "max           25.641731          24.576513          24.003175       1.000000   \n",
       "\n",
       "         Interval_30  \n",
       "count  197436.000000  \n",
       "mean       14.263331  \n",
       "std         2.754295  \n",
       "min         9.000000  \n",
       "25%        12.000000  \n",
       "50%        14.000000  \n",
       "75%        17.000000  \n",
       "max        19.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df=pd.read_csv('/Users/algotsjoholm/Downloads/evalpreproV3.csv',sep=';') #change\n",
    "eval_df = eval_df.dropna()\n",
    "eval_df.describe()\n",
    "#eval_df = eval_df[eval_df['PORTAL'] == 'E4S 58,140']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "Ln9y5STNFD6d",
    "outputId": "a42cacbd-2408-4eb2-b5e2-9202258eaadd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PORTAL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Interval_1</th>\n",
       "      <th>FLOW_SUM</th>\n",
       "      <th>SPEED_WEIGHTED_AVG</th>\n",
       "      <th>FLOW_NEXT_15_SUM</th>\n",
       "      <th>FLOW_PREV_5_SUM</th>\n",
       "      <th>FLOW_PREV_15_SUM</th>\n",
       "      <th>FLOW_PREV_60_SUM</th>\n",
       "      <th>SPEED_NEXT_15_AVG</th>\n",
       "      <th>SPEED_PREV_5_AVG</th>\n",
       "      <th>SPEED_PREV_15_AVG</th>\n",
       "      <th>SPEED_PREV_60_AVG</th>\n",
       "      <th>IS_WEEKDAY</th>\n",
       "      <th>Interval_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>E4S 55,620</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>299</td>\n",
       "      <td>46.0</td>\n",
       "      <td>21.201522</td>\n",
       "      <td>809.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>3031.0</td>\n",
       "      <td>20.327355</td>\n",
       "      <td>20.489483</td>\n",
       "      <td>20.748605</td>\n",
       "      <td>20.927258</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>E4S 55,620</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>300</td>\n",
       "      <td>52.0</td>\n",
       "      <td>20.211538</td>\n",
       "      <td>799.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>20.400551</td>\n",
       "      <td>20.472538</td>\n",
       "      <td>20.694453</td>\n",
       "      <td>20.907895</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>E4S 55,620</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>301</td>\n",
       "      <td>43.0</td>\n",
       "      <td>19.920930</td>\n",
       "      <td>803.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>20.416276</td>\n",
       "      <td>20.279102</td>\n",
       "      <td>20.584840</td>\n",
       "      <td>20.885396</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>E4S 55,620</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>302</td>\n",
       "      <td>51.0</td>\n",
       "      <td>19.504314</td>\n",
       "      <td>823.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>20.347728</td>\n",
       "      <td>20.111063</td>\n",
       "      <td>20.494610</td>\n",
       "      <td>20.854199</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>E4S 55,620</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>303</td>\n",
       "      <td>51.0</td>\n",
       "      <td>20.606471</td>\n",
       "      <td>825.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>20.304024</td>\n",
       "      <td>20.281975</td>\n",
       "      <td>20.542771</td>\n",
       "      <td>20.830094</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604005</th>\n",
       "      <td>E4S 58,140</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>580</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.883889</td>\n",
       "      <td>272.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>21.605846</td>\n",
       "      <td>21.622043</td>\n",
       "      <td>21.793375</td>\n",
       "      <td>21.557267</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604006</th>\n",
       "      <td>E4S 58,140</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>581</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.212727</td>\n",
       "      <td>280.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>21.614643</td>\n",
       "      <td>21.765195</td>\n",
       "      <td>21.823500</td>\n",
       "      <td>21.566363</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604007</th>\n",
       "      <td>E4S 58,140</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>582</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.908000</td>\n",
       "      <td>293.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>21.522355</td>\n",
       "      <td>21.808551</td>\n",
       "      <td>21.851660</td>\n",
       "      <td>21.582333</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604008</th>\n",
       "      <td>E4S 58,140</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>583</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.883125</td>\n",
       "      <td>300.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>21.543433</td>\n",
       "      <td>21.670704</td>\n",
       "      <td>21.781344</td>\n",
       "      <td>21.582276</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604009</th>\n",
       "      <td>E4S 58,140</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>584</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.006923</td>\n",
       "      <td>306.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>21.563007</td>\n",
       "      <td>21.412192</td>\n",
       "      <td>21.684332</td>\n",
       "      <td>21.573035</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476529 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PORTAL        Date  Interval_1  FLOW_SUM  SPEED_WEIGHTED_AVG  \\\n",
       "59      E4S 55,620  2021-06-01         299      46.0           21.201522   \n",
       "60      E4S 55,620  2021-06-01         300      52.0           20.211538   \n",
       "61      E4S 55,620  2021-06-01         301      43.0           19.920930   \n",
       "62      E4S 55,620  2021-06-01         302      51.0           19.504314   \n",
       "63      E4S 55,620  2021-06-01         303      51.0           20.606471   \n",
       "...            ...         ...         ...       ...                 ...   \n",
       "604005  E4S 58,140  2021-12-31         580      18.0           21.883889   \n",
       "604006  E4S 58,140  2021-12-31         581      11.0           21.212727   \n",
       "604007  E4S 58,140  2021-12-31         582      15.0           21.908000   \n",
       "604008  E4S 58,140  2021-12-31         583      16.0           20.883125   \n",
       "604009  E4S 58,140  2021-12-31         584      13.0           21.006923   \n",
       "\n",
       "        FLOW_NEXT_15_SUM  FLOW_PREV_5_SUM  FLOW_PREV_15_SUM  FLOW_PREV_60_SUM  \\\n",
       "59                 809.0            271.0             817.0            3031.0   \n",
       "60                 799.0            260.0             822.0            3054.0   \n",
       "61                 803.0            256.0             814.0            3071.0   \n",
       "62                 823.0            254.0             807.0            3084.0   \n",
       "63                 825.0            243.0             783.0            3101.0   \n",
       "...                  ...              ...               ...               ...   \n",
       "604005             272.0             93.0             240.0             827.0   \n",
       "604006             280.0             77.0             240.0             822.0   \n",
       "604007             293.0             69.0             247.0             823.0   \n",
       "604008             300.0             71.0             253.0             826.0   \n",
       "604009             306.0             73.0             247.0             827.0   \n",
       "\n",
       "        SPEED_NEXT_15_AVG  SPEED_PREV_5_AVG  SPEED_PREV_15_AVG  \\\n",
       "59              20.327355         20.489483          20.748605   \n",
       "60              20.400551         20.472538          20.694453   \n",
       "61              20.416276         20.279102          20.584840   \n",
       "62              20.347728         20.111063          20.494610   \n",
       "63              20.304024         20.281975          20.542771   \n",
       "...                   ...               ...                ...   \n",
       "604005          21.605846         21.622043          21.793375   \n",
       "604006          21.614643         21.765195          21.823500   \n",
       "604007          21.522355         21.808551          21.851660   \n",
       "604008          21.543433         21.670704          21.781344   \n",
       "604009          21.563007         21.412192          21.684332   \n",
       "\n",
       "        SPEED_PREV_60_AVG  IS_WEEKDAY  Interval_30  \n",
       "59              20.927258           1            9  \n",
       "60              20.907895           1           10  \n",
       "61              20.885396           1           10  \n",
       "62              20.854199           1           10  \n",
       "63              20.830094           1           10  \n",
       "...                   ...         ...          ...  \n",
       "604005          21.557267           0           19  \n",
       "604006          21.566363           0           19  \n",
       "604007          21.582333           0           19  \n",
       "604008          21.582276           0           19  \n",
       "604009          21.573035           0           19  \n",
       "\n",
       "[476529 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df\n",
    "#train_df = train_df[train_df['PORTAL'] == 'E4S 58,140']\n",
    "#train_df  = train_df[(train_df['Interval_1'] > 450) & (train_df['Interval_1'] <=510)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "C7ICXTebCRkj",
    "outputId": "c1578157-8b4c-4c1f-d84e-b6022db0fb78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PORTAL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Interval_1</th>\n",
       "      <th>FLOW_SUM</th>\n",
       "      <th>SPEED_WEIGHTED_AVG</th>\n",
       "      <th>FLOW_NEXT_15_SUM</th>\n",
       "      <th>FLOW_PREV_5_SUM</th>\n",
       "      <th>FLOW_PREV_15_SUM</th>\n",
       "      <th>FLOW_PREV_60_SUM</th>\n",
       "      <th>SPEED_NEXT_15_AVG</th>\n",
       "      <th>SPEED_PREV_5_AVG</th>\n",
       "      <th>SPEED_PREV_15_AVG</th>\n",
       "      <th>SPEED_PREV_60_AVG</th>\n",
       "      <th>IS_WEEKDAY</th>\n",
       "      <th>Interval_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E4S 55,620</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>451</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.723529</td>\n",
       "      <td>535.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>19.667645</td>\n",
       "      <td>19.924590</td>\n",
       "      <td>19.637822</td>\n",
       "      <td>19.783167</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E4S 55,620</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>452</td>\n",
       "      <td>39.0</td>\n",
       "      <td>19.423846</td>\n",
       "      <td>542.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2263.0</td>\n",
       "      <td>19.636033</td>\n",
       "      <td>19.861907</td>\n",
       "      <td>19.577645</td>\n",
       "      <td>19.760420</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E4S 55,620</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>453</td>\n",
       "      <td>44.0</td>\n",
       "      <td>18.888636</td>\n",
       "      <td>532.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>19.726297</td>\n",
       "      <td>19.685436</td>\n",
       "      <td>19.528818</td>\n",
       "      <td>19.752407</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E4S 55,620</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>454</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.148571</td>\n",
       "      <td>535.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>2260.0</td>\n",
       "      <td>19.648710</td>\n",
       "      <td>19.564974</td>\n",
       "      <td>19.529261</td>\n",
       "      <td>19.732009</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E4S 55,620</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>455</td>\n",
       "      <td>38.0</td>\n",
       "      <td>19.536842</td>\n",
       "      <td>524.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>19.717195</td>\n",
       "      <td>19.504368</td>\n",
       "      <td>19.555647</td>\n",
       "      <td>19.708859</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41545</th>\n",
       "      <td>E4S 58,140</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>506</td>\n",
       "      <td>66.0</td>\n",
       "      <td>21.448182</td>\n",
       "      <td>919.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>3768.0</td>\n",
       "      <td>21.302590</td>\n",
       "      <td>21.522667</td>\n",
       "      <td>21.300666</td>\n",
       "      <td>21.365154</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41546</th>\n",
       "      <td>E4S 58,140</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>507</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.661600</td>\n",
       "      <td>933.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>21.347824</td>\n",
       "      <td>21.233344</td>\n",
       "      <td>21.265068</td>\n",
       "      <td>21.355133</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41547</th>\n",
       "      <td>E4S 58,140</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>508</td>\n",
       "      <td>77.0</td>\n",
       "      <td>19.574805</td>\n",
       "      <td>921.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>21.481379</td>\n",
       "      <td>21.013943</td>\n",
       "      <td>21.180227</td>\n",
       "      <td>21.318696</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41548</th>\n",
       "      <td>E4S 58,140</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>509</td>\n",
       "      <td>49.0</td>\n",
       "      <td>22.113673</td>\n",
       "      <td>944.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>3757.0</td>\n",
       "      <td>21.406324</td>\n",
       "      <td>21.037599</td>\n",
       "      <td>21.176419</td>\n",
       "      <td>21.330000</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41549</th>\n",
       "      <td>E4S 58,140</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>510</td>\n",
       "      <td>58.0</td>\n",
       "      <td>21.759655</td>\n",
       "      <td>941.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>3734.0</td>\n",
       "      <td>21.370978</td>\n",
       "      <td>21.005167</td>\n",
       "      <td>21.258800</td>\n",
       "      <td>21.348361</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41550 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PORTAL        Date  Interval_1  FLOW_SUM  SPEED_WEIGHTED_AVG  \\\n",
       "0      E4S 55,620  2022-01-05         451      34.0           20.723529   \n",
       "1      E4S 55,620  2022-01-05         452      39.0           19.423846   \n",
       "2      E4S 55,620  2022-01-05         453      44.0           18.888636   \n",
       "3      E4S 55,620  2022-01-05         454      35.0           19.148571   \n",
       "4      E4S 55,620  2022-01-05         455      38.0           19.536842   \n",
       "...           ...         ...         ...       ...                 ...   \n",
       "41545  E4S 58,140  2022-06-30         506      66.0           21.448182   \n",
       "41546  E4S 58,140  2022-06-30         507      50.0           20.661600   \n",
       "41547  E4S 58,140  2022-06-30         508      77.0           19.574805   \n",
       "41548  E4S 58,140  2022-06-30         509      49.0           22.113673   \n",
       "41549  E4S 58,140  2022-06-30         510      58.0           21.759655   \n",
       "\n",
       "       FLOW_NEXT_15_SUM  FLOW_PREV_5_SUM  FLOW_PREV_15_SUM  FLOW_PREV_60_SUM  \\\n",
       "0                 535.0            183.0             528.0            2264.0   \n",
       "1                 542.0            194.0             535.0            2263.0   \n",
       "2                 532.0            195.0             550.0            2264.0   \n",
       "3                 535.0            193.0             541.0            2260.0   \n",
       "4                 524.0            190.0             549.0            2261.0   \n",
       "...                 ...              ...               ...               ...   \n",
       "41545             919.0            330.0             946.0            3768.0   \n",
       "41546             933.0            302.0             959.0            3760.0   \n",
       "41547             921.0            317.0             970.0            3780.0   \n",
       "41548             944.0            304.0             944.0            3757.0   \n",
       "41549             941.0            300.0             950.0            3734.0   \n",
       "\n",
       "       SPEED_NEXT_15_AVG  SPEED_PREV_5_AVG  SPEED_PREV_15_AVG  \\\n",
       "0              19.667645         19.924590          19.637822   \n",
       "1              19.636033         19.861907          19.577645   \n",
       "2              19.726297         19.685436          19.528818   \n",
       "3              19.648710         19.564974          19.529261   \n",
       "4              19.717195         19.504368          19.555647   \n",
       "...                  ...               ...                ...   \n",
       "41545          21.302590         21.522667          21.300666   \n",
       "41546          21.347824         21.233344          21.265068   \n",
       "41547          21.481379         21.013943          21.180227   \n",
       "41548          21.406324         21.037599          21.176419   \n",
       "41549          21.370978         21.005167          21.258800   \n",
       "\n",
       "       SPEED_PREV_60_AVG  IS_WEEKDAY  Interval_30  \n",
       "0              19.783167           1           15  \n",
       "1              19.760420           1           15  \n",
       "2              19.752407           1           15  \n",
       "3              19.732009           1           15  \n",
       "4              19.708859           1           15  \n",
       "...                  ...         ...          ...  \n",
       "41545          21.365154           1           16  \n",
       "41546          21.355133           1           16  \n",
       "41547          21.318696           1           16  \n",
       "41548          21.330000           1           16  \n",
       "41549          21.348361           1           17  \n",
       "\n",
       "[41550 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_eval_df=pd.read_csv('/Users/algotsjoholm/Downloads/peakevalpreproV2.csv',sep=';') #change\n",
    "peak_eval_df = peak_eval_df.dropna()\n",
    "peak_eval_df\n",
    "#peak_eval_df = peak_eval_df[peak_eval_df['PORTAL'] == 'E4S 58,140']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qs2_rxt4CRnR",
    "outputId": "f81f2f49-1aee-4ea1-831b-41f6f327650b"
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'FLOW_NEXT_15_SUM',\n",
    "    'SPEED_NEXT_15_AVG',\n",
    "    #'FLOW_SUM',\n",
    "    #'SPEED_WEIGHTED_AVG',\n",
    "    'FLOW_PREV_5_SUM',\n",
    "    'FLOW_PREV_15_SUM',\n",
    "    'FLOW_PREV_60_SUM'#,\n",
    "    #'SPEED_PREV_5_AVG',\n",
    "    #'SPEED_PREV_15_AVG',\n",
    "    #'SPEED_PREV_60_AVG',\n",
    "    #'IS_WEEKDAY',\n",
    "    #'Interval_30'\n",
    "]\n",
    "\n",
    "train_df = train_df[features]\n",
    "#train_df = train_df.iloc[:30000]\n",
    "\n",
    "x = train_df.drop(['FLOW_NEXT_15_SUM', 'SPEED_NEXT_15_AVG'], axis=1)\n",
    "\n",
    "#y = train_df[['FLOW_NEXT_15_SUM', 'SPEED_NEXT_15_AVG']]\n",
    "y = train_df['FLOW_NEXT_15_SUM']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train = scaler_x.fit_transform(X_train)\n",
    "X_test = scaler_x.transform(X_test)\n",
    "\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "#y_train = scaler_y.fit_transform(y_train)\n",
    "#y_test = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHCeaDB5RCNC",
    "outputId": "4824f5d4-9334-4744-d1a9-55d2685fbec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/tune_exponential_units2/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(units=hp.Choice('l1_units', values=[32, 64, 128, 256]), \n",
    "                    activation=hp.Choice('activation_1', ['relu', 'tanh']),\n",
    "                    input_dim=X_train.shape[1]))\n",
    "\n",
    "    for i in range(hp.Int('num_layers', 1, 2)):\n",
    "        model.add(Dense(units=hp.Choice(f'l{i+2}_units', values=[32, 64, 128, 256]),\n",
    "                        activation=hp.Choice(f'activation_{i+2}', ['relu', 'tanh'])))\n",
    "        #model.add(Dropout(rate=hp.Choice(f'dropout_{i+2}', values=[0.0, 0.2])))\n",
    "\n",
    "    #model.add(Dense(2))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
    "        loss='mae',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_mae',\n",
    "                     max_epochs=50,\n",
    "                     factor=3,\n",
    "                     seed=42,\n",
    "                     directory='my_dir',\n",
    "                     project_name='tune_exponential_units2')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_mae', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mae', factor=0.5, patience=3)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, batch_size=32, callbacks=[early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "q17Fr5emXtya"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_units: 64\n",
      "activation_1: tanh\n",
      "num_layers: 2\n",
      "l2_units: 256\n",
      "activation_2: relu\n",
      "learning_rate: 0.002269730362400285\n",
      "l3_units: 128\n",
      "activation_3: tanh\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 17\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0080\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "for hp_name, hp_value in best_hps.values.items():\n",
    "    print(f\"{hp_name}: {hp_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OGhFpKBSR-Ds"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/algotsjoholm/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 657us/step - loss: 270.8999 - mae: 270.8999 - val_loss: 46.3667 - val_mae: 46.3667 - learning_rate: 0.0023\n",
      "Epoch 2/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 656us/step - loss: 45.7076 - mae: 45.7076 - val_loss: 47.7465 - val_mae: 47.7465 - learning_rate: 0.0023\n",
      "Epoch 3/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 666us/step - loss: 44.9957 - mae: 44.9957 - val_loss: 44.0118 - val_mae: 44.0118 - learning_rate: 0.0023\n",
      "Epoch 4/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 700us/step - loss: 44.5948 - mae: 44.5948 - val_loss: 45.2368 - val_mae: 45.2368 - learning_rate: 0.0023\n",
      "Epoch 5/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 668us/step - loss: 44.4147 - mae: 44.4147 - val_loss: 45.0742 - val_mae: 45.0742 - learning_rate: 0.0023\n",
      "Epoch 6/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 706us/step - loss: 44.2271 - mae: 44.2271 - val_loss: 44.4238 - val_mae: 44.4238 - learning_rate: 0.0023\n",
      "Epoch 7/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 673us/step - loss: 43.5138 - mae: 43.5138 - val_loss: 43.3260 - val_mae: 43.3260 - learning_rate: 0.0011\n",
      "Epoch 8/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 674us/step - loss: 43.5090 - mae: 43.5090 - val_loss: 43.1282 - val_mae: 43.1282 - learning_rate: 0.0011\n",
      "Epoch 9/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 645us/step - loss: 43.3830 - mae: 43.3830 - val_loss: 43.3670 - val_mae: 43.3670 - learning_rate: 0.0011\n",
      "Epoch 10/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 650us/step - loss: 43.3915 - mae: 43.3915 - val_loss: 43.2335 - val_mae: 43.2335 - learning_rate: 0.0011\n",
      "Epoch 11/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 649us/step - loss: 43.3553 - mae: 43.3553 - val_loss: 43.1255 - val_mae: 43.1255 - learning_rate: 0.0011\n",
      "Epoch 12/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 734us/step - loss: 43.2824 - mae: 43.2824 - val_loss: 43.3350 - val_mae: 43.3350 - learning_rate: 0.0011\n",
      "Epoch 13/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 678us/step - loss: 43.3308 - mae: 43.3308 - val_loss: 43.4860 - val_mae: 43.4860 - learning_rate: 0.0011\n",
      "Epoch 14/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 702us/step - loss: 43.3003 - mae: 43.3003 - val_loss: 43.2270 - val_mae: 43.2270 - learning_rate: 0.0011\n",
      "Epoch 15/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 696us/step - loss: 42.8732 - mae: 42.8732 - val_loss: 42.8891 - val_mae: 42.8891 - learning_rate: 5.6743e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 715us/step - loss: 42.8838 - mae: 42.8838 - val_loss: 42.7692 - val_mae: 42.7692 - learning_rate: 5.6743e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 708us/step - loss: 42.7811 - mae: 42.7811 - val_loss: 43.1505 - val_mae: 43.1505 - learning_rate: 5.6743e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 711us/step - loss: 42.9064 - mae: 42.9064 - val_loss: 42.7768 - val_mae: 42.7768 - learning_rate: 5.6743e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 746us/step - loss: 42.8316 - mae: 42.8316 - val_loss: 42.8839 - val_mae: 42.8839 - learning_rate: 5.6743e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 765us/step - loss: 42.5165 - mae: 42.5165 - val_loss: 42.6015 - val_mae: 42.6015 - learning_rate: 2.8372e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 753us/step - loss: 42.5674 - mae: 42.5674 - val_loss: 42.7421 - val_mae: 42.7421 - learning_rate: 2.8372e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 739us/step - loss: 42.5925 - mae: 42.5925 - val_loss: 42.5838 - val_mae: 42.5838 - learning_rate: 2.8372e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 787us/step - loss: 42.5447 - mae: 42.5447 - val_loss: 42.6171 - val_mae: 42.6171 - learning_rate: 2.8372e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 739us/step - loss: 42.6927 - mae: 42.6927 - val_loss: 42.6310 - val_mae: 42.6310 - learning_rate: 2.8372e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 736us/step - loss: 42.5256 - mae: 42.5256 - val_loss: 42.5967 - val_mae: 42.5967 - learning_rate: 2.8372e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 747us/step - loss: 42.4645 - mae: 42.4645 - val_loss: 42.5727 - val_mae: 42.5727 - learning_rate: 1.4186e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 739us/step - loss: 42.5350 - mae: 42.5350 - val_loss: 42.5989 - val_mae: 42.5989 - learning_rate: 1.4186e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 781us/step - loss: 42.4644 - mae: 42.4644 - val_loss: 42.5801 - val_mae: 42.5801 - learning_rate: 1.4186e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 758us/step - loss: 42.4652 - mae: 42.4652 - val_loss: 42.5159 - val_mae: 42.5159 - learning_rate: 1.4186e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 785us/step - loss: 42.5556 - mae: 42.5556 - val_loss: 42.4970 - val_mae: 42.4970 - learning_rate: 1.4186e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 756us/step - loss: 42.5418 - mae: 42.5418 - val_loss: 42.5847 - val_mae: 42.5847 - learning_rate: 1.4186e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 731us/step - loss: 42.4023 - mae: 42.4023 - val_loss: 42.6463 - val_mae: 42.6463 - learning_rate: 1.4186e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 758us/step - loss: 42.4079 - mae: 42.4079 - val_loss: 42.4987 - val_mae: 42.4987 - learning_rate: 1.4186e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 773us/step - loss: 42.3757 - mae: 42.3757 - val_loss: 42.5059 - val_mae: 42.5059 - learning_rate: 7.0929e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 743us/step - loss: 42.4819 - mae: 42.4819 - val_loss: 42.4944 - val_mae: 42.4944 - learning_rate: 7.0929e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 744us/step - loss: 42.3848 - mae: 42.3848 - val_loss: 42.4954 - val_mae: 42.4954 - learning_rate: 7.0929e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 766us/step - loss: 42.4036 - mae: 42.4036 - val_loss: 42.4949 - val_mae: 42.4949 - learning_rate: 7.0929e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 785us/step - loss: 42.4166 - mae: 42.4166 - val_loss: 42.4926 - val_mae: 42.4926 - learning_rate: 7.0929e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 764us/step - loss: 42.3790 - mae: 42.3790 - val_loss: 42.5225 - val_mae: 42.5225 - learning_rate: 7.0929e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 734us/step - loss: 42.4122 - mae: 42.4122 - val_loss: 42.4894 - val_mae: 42.4894 - learning_rate: 7.0929e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 727us/step - loss: 42.3796 - mae: 42.3796 - val_loss: 42.4699 - val_mae: 42.4699 - learning_rate: 7.0929e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 726us/step - loss: 42.3962 - mae: 42.3962 - val_loss: 42.4803 - val_mae: 42.4803 - learning_rate: 7.0929e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 736us/step - loss: 42.2782 - mae: 42.2782 - val_loss: 42.4875 - val_mae: 42.4875 - learning_rate: 7.0929e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 735us/step - loss: 42.3885 - mae: 42.3885 - val_loss: 42.4837 - val_mae: 42.4837 - learning_rate: 7.0929e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 742us/step - loss: 42.3399 - mae: 42.3399 - val_loss: 42.4619 - val_mae: 42.4619 - learning_rate: 3.5465e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 729us/step - loss: 42.4516 - mae: 42.4516 - val_loss: 42.4625 - val_mae: 42.4625 - learning_rate: 3.5465e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 689us/step - loss: 42.3960 - mae: 42.3960 - val_loss: 42.4671 - val_mae: 42.4671 - learning_rate: 3.5465e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 694us/step - loss: 42.2976 - mae: 42.2976 - val_loss: 42.4728 - val_mae: 42.4728 - learning_rate: 3.5465e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 699us/step - loss: 42.2884 - mae: 42.2884 - val_loss: 42.4639 - val_mae: 42.4639 - learning_rate: 1.7732e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m9531/9531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 717us/step - loss: 42.3650 - mae: 42.3650 - val_loss: 42.4609 - val_mae: 42.4609 - learning_rate: 1.7732e-05\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=50, validation_split=0.2, batch_size=32, callbacks=[early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kvJDoE19R--c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.370270</td>\n",
       "      <td>130.370270</td>\n",
       "      <td>46.366707</td>\n",
       "      <td>46.366707</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.476059</td>\n",
       "      <td>45.476059</td>\n",
       "      <td>47.746540</td>\n",
       "      <td>47.746540</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.924328</td>\n",
       "      <td>44.924328</td>\n",
       "      <td>44.011826</td>\n",
       "      <td>44.011826</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.600754</td>\n",
       "      <td>44.600754</td>\n",
       "      <td>45.236797</td>\n",
       "      <td>45.236797</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.383789</td>\n",
       "      <td>44.383789</td>\n",
       "      <td>45.074181</td>\n",
       "      <td>45.074181</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44.256298</td>\n",
       "      <td>44.256298</td>\n",
       "      <td>44.423767</td>\n",
       "      <td>44.423767</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43.535957</td>\n",
       "      <td>43.535957</td>\n",
       "      <td>43.325996</td>\n",
       "      <td>43.325996</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43.429020</td>\n",
       "      <td>43.429020</td>\n",
       "      <td>43.128170</td>\n",
       "      <td>43.128170</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43.395687</td>\n",
       "      <td>43.395687</td>\n",
       "      <td>43.367046</td>\n",
       "      <td>43.367046</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43.366497</td>\n",
       "      <td>43.366497</td>\n",
       "      <td>43.233459</td>\n",
       "      <td>43.233459</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>43.297100</td>\n",
       "      <td>43.297100</td>\n",
       "      <td>43.125515</td>\n",
       "      <td>43.125515</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>43.286011</td>\n",
       "      <td>43.286011</td>\n",
       "      <td>43.334972</td>\n",
       "      <td>43.334972</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>43.257355</td>\n",
       "      <td>43.257355</td>\n",
       "      <td>43.486031</td>\n",
       "      <td>43.486031</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43.228539</td>\n",
       "      <td>43.228539</td>\n",
       "      <td>43.226986</td>\n",
       "      <td>43.226986</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>42.886490</td>\n",
       "      <td>42.886490</td>\n",
       "      <td>42.889133</td>\n",
       "      <td>42.889133</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>42.865723</td>\n",
       "      <td>42.865723</td>\n",
       "      <td>42.769207</td>\n",
       "      <td>42.769207</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>42.831009</td>\n",
       "      <td>42.831009</td>\n",
       "      <td>43.150459</td>\n",
       "      <td>43.150459</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>42.837284</td>\n",
       "      <td>42.837284</td>\n",
       "      <td>42.776833</td>\n",
       "      <td>42.776833</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>42.817863</td>\n",
       "      <td>42.817863</td>\n",
       "      <td>42.883873</td>\n",
       "      <td>42.883873</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>42.625053</td>\n",
       "      <td>42.625053</td>\n",
       "      <td>42.601528</td>\n",
       "      <td>42.601528</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>42.623913</td>\n",
       "      <td>42.623913</td>\n",
       "      <td>42.742069</td>\n",
       "      <td>42.742069</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>42.615498</td>\n",
       "      <td>42.615498</td>\n",
       "      <td>42.583801</td>\n",
       "      <td>42.583801</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42.592205</td>\n",
       "      <td>42.592205</td>\n",
       "      <td>42.617134</td>\n",
       "      <td>42.617134</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>42.599964</td>\n",
       "      <td>42.599964</td>\n",
       "      <td>42.631020</td>\n",
       "      <td>42.631020</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>42.589634</td>\n",
       "      <td>42.589634</td>\n",
       "      <td>42.596695</td>\n",
       "      <td>42.596695</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>42.499222</td>\n",
       "      <td>42.499222</td>\n",
       "      <td>42.572731</td>\n",
       "      <td>42.572731</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>42.490005</td>\n",
       "      <td>42.490005</td>\n",
       "      <td>42.598904</td>\n",
       "      <td>42.598904</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42.485130</td>\n",
       "      <td>42.485130</td>\n",
       "      <td>42.580082</td>\n",
       "      <td>42.580082</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>42.475471</td>\n",
       "      <td>42.475471</td>\n",
       "      <td>42.515865</td>\n",
       "      <td>42.515865</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>42.473522</td>\n",
       "      <td>42.473522</td>\n",
       "      <td>42.497025</td>\n",
       "      <td>42.497025</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>42.472733</td>\n",
       "      <td>42.472733</td>\n",
       "      <td>42.584694</td>\n",
       "      <td>42.584694</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>42.468681</td>\n",
       "      <td>42.468681</td>\n",
       "      <td>42.646278</td>\n",
       "      <td>42.646278</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>42.461842</td>\n",
       "      <td>42.461842</td>\n",
       "      <td>42.498711</td>\n",
       "      <td>42.498711</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>42.414074</td>\n",
       "      <td>42.414074</td>\n",
       "      <td>42.505894</td>\n",
       "      <td>42.505894</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>42.413258</td>\n",
       "      <td>42.413258</td>\n",
       "      <td>42.494427</td>\n",
       "      <td>42.494427</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>42.408905</td>\n",
       "      <td>42.408905</td>\n",
       "      <td>42.495358</td>\n",
       "      <td>42.495358</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>42.407024</td>\n",
       "      <td>42.407024</td>\n",
       "      <td>42.494904</td>\n",
       "      <td>42.494904</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>42.407707</td>\n",
       "      <td>42.407707</td>\n",
       "      <td>42.492611</td>\n",
       "      <td>42.492611</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>42.404892</td>\n",
       "      <td>42.404892</td>\n",
       "      <td>42.522484</td>\n",
       "      <td>42.522484</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>42.399483</td>\n",
       "      <td>42.399483</td>\n",
       "      <td>42.489368</td>\n",
       "      <td>42.489368</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>42.402531</td>\n",
       "      <td>42.402531</td>\n",
       "      <td>42.469868</td>\n",
       "      <td>42.469868</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.394554</td>\n",
       "      <td>42.394554</td>\n",
       "      <td>42.480305</td>\n",
       "      <td>42.480305</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42.393372</td>\n",
       "      <td>42.393372</td>\n",
       "      <td>42.487534</td>\n",
       "      <td>42.487534</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>42.398270</td>\n",
       "      <td>42.398270</td>\n",
       "      <td>42.483711</td>\n",
       "      <td>42.483711</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>42.370853</td>\n",
       "      <td>42.370853</td>\n",
       "      <td>42.461910</td>\n",
       "      <td>42.461910</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>42.369095</td>\n",
       "      <td>42.369095</td>\n",
       "      <td>42.462547</td>\n",
       "      <td>42.462547</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>42.366577</td>\n",
       "      <td>42.366577</td>\n",
       "      <td>42.467129</td>\n",
       "      <td>42.467129</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>42.365852</td>\n",
       "      <td>42.365852</td>\n",
       "      <td>42.472778</td>\n",
       "      <td>42.472778</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>42.353943</td>\n",
       "      <td>42.353943</td>\n",
       "      <td>42.463932</td>\n",
       "      <td>42.463932</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>42.352516</td>\n",
       "      <td>42.352516</td>\n",
       "      <td>42.460869</td>\n",
       "      <td>42.460869</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss         mae   val_loss    val_mae  learning_rate\n",
       "0   130.370270  130.370270  46.366707  46.366707       0.002270\n",
       "1    45.476059   45.476059  47.746540  47.746540       0.002270\n",
       "2    44.924328   44.924328  44.011826  44.011826       0.002270\n",
       "3    44.600754   44.600754  45.236797  45.236797       0.002270\n",
       "4    44.383789   44.383789  45.074181  45.074181       0.002270\n",
       "5    44.256298   44.256298  44.423767  44.423767       0.002270\n",
       "6    43.535957   43.535957  43.325996  43.325996       0.001135\n",
       "7    43.429020   43.429020  43.128170  43.128170       0.001135\n",
       "8    43.395687   43.395687  43.367046  43.367046       0.001135\n",
       "9    43.366497   43.366497  43.233459  43.233459       0.001135\n",
       "10   43.297100   43.297100  43.125515  43.125515       0.001135\n",
       "11   43.286011   43.286011  43.334972  43.334972       0.001135\n",
       "12   43.257355   43.257355  43.486031  43.486031       0.001135\n",
       "13   43.228539   43.228539  43.226986  43.226986       0.001135\n",
       "14   42.886490   42.886490  42.889133  42.889133       0.000567\n",
       "15   42.865723   42.865723  42.769207  42.769207       0.000567\n",
       "16   42.831009   42.831009  43.150459  43.150459       0.000567\n",
       "17   42.837284   42.837284  42.776833  42.776833       0.000567\n",
       "18   42.817863   42.817863  42.883873  42.883873       0.000567\n",
       "19   42.625053   42.625053  42.601528  42.601528       0.000284\n",
       "20   42.623913   42.623913  42.742069  42.742069       0.000284\n",
       "21   42.615498   42.615498  42.583801  42.583801       0.000284\n",
       "22   42.592205   42.592205  42.617134  42.617134       0.000284\n",
       "23   42.599964   42.599964  42.631020  42.631020       0.000284\n",
       "24   42.589634   42.589634  42.596695  42.596695       0.000284\n",
       "25   42.499222   42.499222  42.572731  42.572731       0.000142\n",
       "26   42.490005   42.490005  42.598904  42.598904       0.000142\n",
       "27   42.485130   42.485130  42.580082  42.580082       0.000142\n",
       "28   42.475471   42.475471  42.515865  42.515865       0.000142\n",
       "29   42.473522   42.473522  42.497025  42.497025       0.000142\n",
       "30   42.472733   42.472733  42.584694  42.584694       0.000142\n",
       "31   42.468681   42.468681  42.646278  42.646278       0.000142\n",
       "32   42.461842   42.461842  42.498711  42.498711       0.000142\n",
       "33   42.414074   42.414074  42.505894  42.505894       0.000071\n",
       "34   42.413258   42.413258  42.494427  42.494427       0.000071\n",
       "35   42.408905   42.408905  42.495358  42.495358       0.000071\n",
       "36   42.407024   42.407024  42.494904  42.494904       0.000071\n",
       "37   42.407707   42.407707  42.492611  42.492611       0.000071\n",
       "38   42.404892   42.404892  42.522484  42.522484       0.000071\n",
       "39   42.399483   42.399483  42.489368  42.489368       0.000071\n",
       "40   42.402531   42.402531  42.469868  42.469868       0.000071\n",
       "41   42.394554   42.394554  42.480305  42.480305       0.000071\n",
       "42   42.393372   42.393372  42.487534  42.487534       0.000071\n",
       "43   42.398270   42.398270  42.483711  42.483711       0.000071\n",
       "44   42.370853   42.370853  42.461910  42.461910       0.000035\n",
       "45   42.369095   42.369095  42.462547  42.462547       0.000035\n",
       "46   42.366577   42.366577  42.467129  42.467129       0.000035\n",
       "47   42.365852   42.365852  42.472778  42.472778       0.000035\n",
       "48   42.353943   42.353943  42.463932  42.463932       0.000018\n",
       "49   42.352516   42.352516  42.460869  42.460869       0.000018"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "N1n-E7o6SDZm"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "\n",
    "err = history.history['mae']\n",
    "val_err = history.history['val_mae']\n",
    "epochs = range(1, len(err) + 1)\n",
    "\n",
    "plt.plot(epochs, err, '-', label='Training MAE')\n",
    "plt.plot(epochs, val_err, ':', label='Validation MAE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TJuuO_cOSKKk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2979/2979\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343us/step\n",
      "--------------------------------------Result from the best model on test data ---------------------------------------------\n",
      "Target 1 - Mean Absolute Error (MAE): 42.543936161785496\n",
      "Target 1 - Mean Squared Error (MSE): 3631.9057037895395\n",
      "Target 1 - R-squared (R^2): 0.9548987447000367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "#y_pred = scaler_y.inverse_transform(y_pred)\n",
    "#y_test = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "'''mae_1 = mean_absolute_error(y_test[:, 0], y_pred[:, 0])\n",
    "mse_1 = mean_squared_error(y_test[:, 0], y_pred[:, 0])\n",
    "r2_1 = r2_score(y_test[:, 0], y_pred[:, 0])\n",
    "\n",
    "# Calculate metrics for the second target variable (e.g., SPEED_NEXT_15_AVG)\n",
    "mae_2 = mean_absolute_error(y_test[:, 1], y_pred[:, 1])\n",
    "mse_2 = mean_squared_error(y_test[:, 1], y_pred[:, 1])\n",
    "r2_2 = r2_score(y_test[:, 1], y_pred[:, 1])\n",
    "\n",
    "# Optionally, calculate the overall mean of the MAE, MSE, and R^2 across both outputs\n",
    "mae_avg = (mae_1 + mae_2) / 2\n",
    "mse_avg = (mse_1 + mse_2) / 2\n",
    "r2_avg = (r2_1 + r2_2) / 2\n",
    "\n",
    "print('--------------------------------------Result from the best model on test data ---------------------------------------------')\n",
    "print(f\"Target 1 - Mean Absolute Error (MAE): {mae_1}\")\n",
    "print(f\"Target 1 - Mean Squared Error (MSE): {mse_1}\")\n",
    "print(f\"Target 1 - R-squared (R^2): {r2_1}\")\n",
    "print()\n",
    "print(f\"Target 2 - Mean Absolute Error (MAE): {mae_2}\")\n",
    "print(f\"Target 2 - Mean Squared Error (MSE): {mse_2}\")\n",
    "print(f\"Target 2 - R-squared (R^2): {r2_2}\")\n",
    "print()\n",
    "print(f\"Average MAE: {mae_avg}\")\n",
    "print(f\"Average MSE: {mse_avg}\")\n",
    "print(f\"Average R-squared: {r2_avg}\")'''\n",
    "\n",
    "mae_1 = mean_absolute_error(y_test, y_pred)\n",
    "mse_1 = mean_squared_error(y_test, y_pred)\n",
    "r2_1 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('--------------------------------------Result from the best model on test data ---------------------------------------------')\n",
    "print(f\"Target 1 - Mean Absolute Error (MAE): {mae_1}\")\n",
    "print(f\"Target 1 - Mean Squared Error (MSE): {mse_1}\")\n",
    "print(f\"Target 1 - R-squared (R^2): {r2_1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEffz_iBTp0R"
   },
   "source": [
    "## Evaluation on Full Final Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Chy40x01TpHB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6170/6170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 323us/step\n",
      "--------------------------------------Result from the best model on test data ---------------------------------------------\n",
      "Target 1 - Mean Absolute Error (MAE): 45.87948171815034\n",
      "Target 1 - Mean Squared Error (MSE): 4394.2031150190605\n",
      "Target 1 - R-squared (R^2): 0.9469649190425139\n"
     ]
    }
   ],
   "source": [
    "eval_df = eval_df[features]\n",
    "\n",
    "x_eval = eval_df.drop(['FLOW_NEXT_15_SUM', 'SPEED_NEXT_15_AVG'], axis=1)\n",
    "#y_eval = eval_df[['FLOW_NEXT_15_SUM', 'SPEED_NEXT_15_AVG']]\n",
    "y_eval = eval_df['FLOW_NEXT_15_SUM']\n",
    "\n",
    "x_eval = scaler_x.transform(x_eval)\n",
    "\n",
    "y_pred = best_model.predict(x_eval)\n",
    "\n",
    "#y_pred = scaler_y.inverse_transform(y_pred)\n",
    "#y_eval = scaler_y.inverse_transform(y_eval)\n",
    "\n",
    "'''mae_1 = mean_absolute_error(y_eval['FLOW_NEXT_15_SUM'], y_pred[:, 0])\n",
    "mse_1 = mean_squared_error(y_eval['FLOW_NEXT_15_SUM'], y_pred[:, 0])\n",
    "r2_1 = r2_score(y_eval['FLOW_NEXT_15_SUM'], y_pred[:, 0])\n",
    "\n",
    "# Calculate metrics for the second target variable (e.g., SPEED_NEXT_15_AVG)\n",
    "mae_2 = mean_absolute_error(y_eval['SPEED_NEXT_15_AVG'], y_pred[:, 1])\n",
    "mse_2 = mean_squared_error(y_eval['SPEED_NEXT_15_AVG'], y_pred[:, 1])\n",
    "r2_2 = r2_score(y_eval['SPEED_NEXT_15_AVG'], y_pred[:, 1])\n",
    "\n",
    "# Optionally, calculate the overall mean of the MAE, MSE, and R^2 across both outputs\n",
    "mae_avg = (mae_1 + mae_2) / 2\n",
    "mse_avg = (mse_1 + mse_2) / 2\n",
    "r2_avg = (r2_1 + r2_2) / 2\n",
    "\n",
    "print('--------------------------------------Result from the best model on test data ---------------------------------------------')\n",
    "print(f\"Target 1 - Mean Absolute Error (MAE): {mae_1}\")\n",
    "print(f\"Target 1 - Mean Squared Error (MSE): {mse_1}\")\n",
    "print(f\"Target 1 - R-squared (R^2): {r2_1}\")\n",
    "print()\n",
    "print(f\"Target 2 - Mean Absolute Error (MAE): {mae_2}\")\n",
    "print(f\"Target 2 - Mean Squared Error (MSE): {mse_2}\")\n",
    "print(f\"Target 2 - R-squared (R^2): {r2_2}\")\n",
    "print()\n",
    "print(f\"Average MAE: {mae_avg}\")\n",
    "print(f\"Average MSE: {mse_avg}\")\n",
    "print(f\"Average R-squared: {r2_avg}\")'''\n",
    "\n",
    "mae_1 = mean_absolute_error(y_eval, y_pred)\n",
    "mse_1 = mean_squared_error(y_eval, y_pred)\n",
    "r2_1 = r2_score(y_eval, y_pred)\n",
    "\n",
    "print('--------------------------------------Result from the best model on test data ---------------------------------------------')\n",
    "print(f\"Target 1 - Mean Absolute Error (MAE): {mae_1}\")\n",
    "print(f\"Target 1 - Mean Squared Error (MSE): {mse_1}\")\n",
    "print(f\"Target 1 - R-squared (R^2): {r2_1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYoYzmS-Wv5U"
   },
   "source": [
    "## Evaluation on Peak Final Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rcvJJTxRWvWC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step\n",
      "--------------------------------------Result from the best model on test data ---------------------------------------------\n",
      "Target 1 - Mean Absolute Error (MAE): 44.23494606403668\n",
      "Target 1 - Mean Squared Error (MSE): 4110.995573162166\n",
      "Target 1 - R-squared (R^2): 0.9391260365669145\n"
     ]
    }
   ],
   "source": [
    "eval_df_peak= peak_eval_df[features]\n",
    "\n",
    "x_eval = eval_df_peak.drop(['FLOW_NEXT_15_SUM', 'SPEED_NEXT_15_AVG'], axis=1)\n",
    "#y_eval = eval_df_peak[['FLOW_NEXT_15_SUM', 'SPEED_NEXT_15_AVG']]\n",
    "y_eval = eval_df_peak['FLOW_NEXT_15_SUM']\n",
    "\n",
    "x_eval = scaler_x.transform(x_eval)\n",
    "\n",
    "#y_pred = scaler_y.inverse_transform(y_pred)\n",
    "#y_eval = scaler_y.inverse_transform(y_eval)\n",
    "\n",
    "y_pred = best_model.predict(x_eval)\n",
    "\n",
    "'''mae_1 = mean_absolute_error(y_eval['FLOW_NEXT_15_SUM'], y_pred[:, 0])\n",
    "mse_1 = mean_squared_error(y_eval['FLOW_NEXT_15_SUM'], y_pred[:, 0])\n",
    "r2_1 = r2_score(y_eval['FLOW_NEXT_15_SUM'], y_pred[:, 0])\n",
    "\n",
    "# Calculate metrics for the second target variable (e.g., SPEED_NEXT_15_AVG)\n",
    "mae_2 = mean_absolute_error(y_eval['SPEED_NEXT_15_AVG'], y_pred[:, 1])\n",
    "mse_2 = mean_squared_error(y_eval['SPEED_NEXT_15_AVG'], y_pred[:, 1])\n",
    "r2_2 = r2_score(y_eval['SPEED_NEXT_15_AVG'], y_pred[:, 1])\n",
    "\n",
    "print('--------------------------------------Result from the best model on test data ---------------------------------------------')\n",
    "print(f\"Target 1 - Mean Absolute Error (MAE): {mae_1}\")\n",
    "print(f\"Target 1 - Mean Squared Error (MSE): {mse_1}\")\n",
    "print(f\"Target 1 - R-squared (R^2): {r2_1}\")\n",
    "print()\n",
    "print(f\"Target 2 - Mean Absolute Error (MAE): {mae_2}\")\n",
    "print(f\"Target 2 - Mean Squared Error (MSE): {mse_2}\")\n",
    "print(f\"Target 2 - R-squared (R^2): {r2_2}\")\n",
    "print()\n",
    "print(f\"Average MAE: {mae_avg}\")\n",
    "print(f\"Average MSE: {mse_avg}\")\n",
    "print(f\"Average R-squared: {r2_avg}\")'''\n",
    "\n",
    "mae_1 = mean_absolute_error(y_eval, y_pred)\n",
    "mse_1 = mean_squared_error(y_eval, y_pred)\n",
    "r2_1 = r2_score(y_eval, y_pred)\n",
    "\n",
    "print('--------------------------------------Result from the best model on test data ---------------------------------------------')\n",
    "print(f\"Target 1 - Mean Absolute Error (MAE): {mae_1}\")\n",
    "print(f\"Target 1 - Mean Squared Error (MSE): {mse_1}\")\n",
    "print(f\"Target 1 - R-squared (R^2): {r2_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Y0xSZK-XUvmB"
   },
   "outputs": [],
   "source": [
    "best_model.save('best_univar_NN_flow_3FeaturesTraining.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
